{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c66d8af8-e7bb-495f-bea7-957e0350f305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import T5Tokenizer, T5Model,T5ForConditionalGeneration, pipeline\n",
    "import math\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2185093d-a2a4-499a-98d8-342cab4c0617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/joshi.at/ppda_project\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "29657cd4-c080-48f1-abd3-cd255031969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ytdataset_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6e0c33c7-d5ba-4f3a-8a02-b90cbd586fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e3fdd60d-e308-415b-9b20-57e8b238043e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>transcript</th>\n",
       "      <th>playlist_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>introduction to vertex ai feature store</td>\n",
       "      <td>priyanka vergadia did you know that most of th...</td>\n",
       "      <td>ai and machine learning with google cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>illuminating the global fishing fleet through ...</td>\n",
       "      <td>speaker  oceanic ecosystems are threatened by ...</td>\n",
       "      <td>ai and machine learning with google cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>hyperparameter tuning on vertex ai</td>\n",
       "      <td>priyanka vergadia hi im priyanka vergadia and ...</td>\n",
       "      <td>ai and machine learning with google cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>endtoend mlops with vertex ai</td>\n",
       "      <td>priyanka vergadia one of the biggest challenge...</td>\n",
       "      <td>ai and machine learning with google cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>transformers explained understand the model be...</td>\n",
       "      <td>so if you remember anything about transformers...</td>\n",
       "      <td>the original transformer was designed for tran...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0            introduction to vertex ai feature store   \n",
       "1           1  illuminating the global fishing fleet through ...   \n",
       "2           2                 hyperparameter tuning on vertex ai   \n",
       "3           3                      endtoend mlops with vertex ai   \n",
       "4           4  transformers explained understand the model be...   \n",
       "\n",
       "                                          transcript  \\\n",
       "0  priyanka vergadia did you know that most of th...   \n",
       "1  speaker  oceanic ecosystems are threatened by ...   \n",
       "2  priyanka vergadia hi im priyanka vergadia and ...   \n",
       "3  priyanka vergadia one of the biggest challenge...   \n",
       "4  so if you remember anything about transformers...   \n",
       "\n",
       "                                       playlist_name  \n",
       "0          ai and machine learning with google cloud  \n",
       "1          ai and machine learning with google cloud  \n",
       "2          ai and machine learning with google cloud  \n",
       "3          ai and machine learning with google cloud  \n",
       "4  the original transformer was designed for tran...  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0962f18-2cc6-48b6-849f-a40e0098c404",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joshi.at/.conda/envs/ath_pytorch/lib/python3.7/site-packages/transformers/models/t5/tokenization_t5.py:173: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd76487b62c94aa8aa590943516c9492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16e16b59-5c7b-497d-a53f-c21437f26ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(tokenizer.decode(chunked_sample[0]), return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e388bbd2-52db-4be5-ba5c-37e83783de73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    3, 15582,   476,  5033, 12048,     3, 16174,  6302, 24605,    10,\n",
       "         3963,    25,   214,    24,   167,    13,     8,    97,  1869,    57,\n",
       "          331,  7004,  1550,   139,     3,   210,  6287,   697,   331,    58,\n",
       "         1537,  3346,     6,    16,  1451,  3867,     6,    84,    19,     3,\n",
       "        21139,  5902,   331,   139,   306,    18,  4497,  3785,  9650,    21,\n",
       "            3,  6858,  2250,     5,   299,    48,   433,    19,   557,    16,\n",
       "        16995,    11,     3,  2160,  8692,     5,  1548,    27,    31,    51,\n",
       "            3,  7855,    63,  5979,     9,     6,    11,    16,    48,   671,\n",
       "           62,    56,  2862,     8,   843,  2428,    28,  1451,  3867,     6,\n",
       "          149,   781, 10354,     3, 16772,  4493,   199,  4602,   135,     6,\n",
       "           11,   217,     3,     9,  1704,  8698,     5,   852,   125,    33,\n",
       "            8,   843,  2428,    28,     3,  6858,   753,    58,    37,   166,\n",
       "           19,    24,    79,    33,   614,    12,   698,    11, 15677,   640,\n",
       "           39,   315,  2245,    13,     8,     3,  6858, 16101,    11,   640,\n",
       "         1195,     6,    84,   772,    16, 19197,  2231,     5,  5212,    19,\n",
       "           24,    34,    19,   614,    12,  1716,    16,   999, 28624,    63,\n",
       "           28,  1364,  1480, 11298,     6,    11,     8,  1025,    19,    24,\n",
       "          132,    19,    46,    16,     9,    26,  3027,   295,     3, 11049,\n",
       "          210,    16,  1451,  2620,   344,   761,    11,  3122,     6,  1086,\n",
       "            6,    84,  4110,    39,   825,   463,    12,    20,  6801,   147,\n",
       "           97,     5,   466,    19,  1776,   213,   781, 10354,     3, 16772,\n",
       "         4493,   639,    16,     5,    94,    31,     7,     3,     9,  1540,\n",
       "         3030,    11,     3, 22927,  1127,    12,   698,     6,  2928,     6,\n",
       "           11,  1716,  1437,  1036,   753,    44,  2643,   640,   315,  2323,\n",
       "          441,    39,  1470,     5,   275,    34,    92,  1691,  1428,     8,\n",
       "           97,    12,   918,    11, 17274,    39,  7833,     3,  6858,  1564,\n",
       "           57,   492,    34,   514,    12,  1865,    11,  7958,    39,     3,\n",
       "         6858,   753,    16,    80,   286,     5,    94,   656,     8,   753,\n",
       "            3, 28147,     6,   514,    12,  1716,     6,    11,  1792,     7,\n",
       "            3, 11049,   210,     5,   852,   752,    31,     7,   217,   149,\n",
       "           12,   356,    34,    95,     5,    86,     8,  8990,     6,    16,\n",
       "          781, 10354,  7833,     6,    62,   217,     8,     3, 16772,  3808,\n",
       "            5,   304,   129,   708,     6,   752,    31,     7,  1214,    30,\n",
       "           48,  7192,    11,  2075,     6,   338,     3, 16772,  4493,  1375,\n",
       "            5,   852,     8,   166,   589,    25,   174,    19,     3,     9,\n",
       "            3, 16772,  4493,     5,   486,     8,    97,    13,    48,  5592,\n",
       "            6,     3, 16772,  4493,    19,    16, 12565,    78,   131,   214,\n",
       "           24,  3345,    30,   116,    25,    31,    60,  3355,    48,     6,\n",
       "          132,   429,    36,    72,   931,    11,  3864,    24,    25,   133,\n",
       "          217,     5,   148,  1178,   482,     3,     9,     3, 16772,  4493,\n",
       "           16,     8,  8990,     6,    78,   752,    31,     7,   169,    48,\n",
       "         3106, 16638,    12,   669,   149,    12,   482,    34,   338,     8,\n",
       "         9579,   439,     5,   100,  3106,  2284,     3,     9,  1974,  5719,\n",
       "          331,   356,    11,     8,  2491,    19,    12,  2412])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(chunked_sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3579737b-b5ba-4c67-b1b7-6bf161e311ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"PRIYANKA VERGADIA: Did you know that most of the time spent by data scientists goes into wrangling data? More specifically, in feature engineering, which is transforming raw data into high-quality input signals for ML models. But this process is often inefficient and brittle. Well I'm Priyanka, and in this video we will identify the key challenges with feature engineering, how Vertex Feature Store help solve them, and see a quick demo. Now what are the key challenges with ML features? The first is that they are hard to share and reuse across your different steps of the ML workflow and across projects, which results in duplicate efforts. Second is that it is hard to serve in production reliably with lower latency, and the third is that there is an inadvertent skew in feature values between training and serving, usually, which causes your model quality to degrade over time. That is exactly where Vertex Feature Store comes in. It's a fully managed and unified solution to share, discover, and serve machine learning features at scale across different teams within your organization. And it also helps reduce the time to build and deploy your AI ML applications by making it easy to manage and organize your ML features in one place. It makes the features reusable, easy to serve, and avoids skew. Now let's see how to set it up. In the console, in Vertex AI, we see the Feature tab. To get started, let's click on this documentation and explore, using Feature Store section. Now the first thing you need is a Feature Store. At the time of this recording, Feature Store is in preview so just know that depending on when you're watching this, there might be more options and updates that you would see. You cannot create a Feature Store in the console, so let's use this sample notebook to learn how to create it using the SDK. This sample uses a movie recommendations data set and the task is to train\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(chunked_sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da85bd9f-22f9-49dd-ba69-9853d23dec6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Priyanka VERGADIA: feature engineering is a time-consuming and inefficient process. Feature Store helps you share, discover, and serve machine learning features at scale. it's a fully managed and unified solution to share, discover, and serve ML features. Feature Store is a fully managed and unified solution to share, discover, and serve machine learning features at scale. Priyanka: 'i'm a big fan of this product, but i\n"
     ]
    }
   ],
   "source": [
    "summary_ids = model.generate(input_ids,\n",
    "                            min_length=100, max_length=500,temperature=0.7\n",
    "                            )\n",
    "# Decode the summary text using the tokenizer\n",
    "summary_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "# Print the summary text\n",
    "print(summary_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19703bdf-ad17-4169-8f04-3132e5d2647e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \"Priyanka VERGADIA shows how vertex Feature Store helps solve key challenges . it's a fully managed and unified solution to share, discover, and serve machine learning features . Feature store makes the features reusable, easy to serve, and avoids skew .\"}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac24cd5a-0bc9-4392-8f3a-119be8dc2771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01a5aa729b544a69f5bfb5a6bfee9e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ec11654a16455698f7e98702da22f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joshi.at/.conda/envs/ath_pytorch/lib/python3.7/site-packages/transformers/models/t5/tokenization_t5.py:173: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-base',return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dcb7120-4fd3-4dbb-bd10-27d545966666",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1312 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1312"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer(df['transcript'][0]).input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "536957c7-3fd6-4268-a363-5a688f932218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4843280767044398ba991d7e02709b7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = T5Model.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4f5be13-6a37-48b6-be74-cbc102ba4857",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_sample = np.array_split(tokenizer(df['transcript'][0]).input_ids,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb7d58f8-a57e-4c32-bba2-d6415ee478c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "437"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunked_sample[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "417cda7c-2de2-487c-ae45-b091ac82dbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joshi.at/.conda/envs/ath_pytorch/lib/python3.7/site-packages/transformers/models/t5/tokenization_t5.py:173: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  FutureWarning,\n",
      "/home/joshi.at/.conda/envs/ath_pytorch/lib/python3.7/site-packages/transformers/models/t5/tokenization_t5_fast.py:165: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# define model, tokenizer and summarization pipeline\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "summarizer_gpu = pipeline(\"summarization\", model=\"t5-base\", tokenizer=\"t5-base\", device=0)\n",
    "summarizer_cpu = pipeline(\"summarization\", model=\"t5-base\", tokenizer=\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "16d451be-e824-4f73-829d-24dd0b109d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summaries(transcript,device,time_store,MAX_LENGTH=500):\n",
    "    full_tokenize = tokenizer(transcript).input_ids\n",
    "    length_sample = len(full_tokenize)\n",
    "    chunks =math.ceil(length_sample/MAX_LENGTH)\n",
    "    chunked_sample = np.array_split(full_tokenize,chunks)\n",
    "    sample_text=\"\"\n",
    "    srz_min_length = 1    # to be considered\n",
    "    srz_max_length = int(MAX_LENGTH/chunks)\n",
    "    if (device==0):\n",
    "        summarizer = summarizer_gpu\n",
    "    else:\n",
    "        summarizer = summarizer_cpu\n",
    "    start = time.time()\n",
    "    for j in chunked_sample:\n",
    "        input_text = tokenizer.decode(j)\n",
    "        sample_text+=summarizer(input_text, min_length=srz_min_length, max_length=srz_max_length)[0]['summary_text']\n",
    "    end = time.time()\n",
    "    time_store.append(end-start)\n",
    "    return sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9f100fa6-fd85-4426-911e-cb15a3200267",
   "metadata": {},
   "outputs": [],
   "source": [
    "script = df['transcript'][3]\n",
    "temp=[]\n",
    "device=0\n",
    "summary = create_summaries(script,device,temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dc8e3121-e5a2-41cc-ab14-a0daa6c96624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.478700637817383]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8fc9768-9532-4f32-986b-f833a0c2dd69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunkedtext = tokenizer.decode(chunked_sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8f0aea-18f8-4cb8-9fc7-436faba61f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunkedtext = tokenizer.decode(chunked_sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a2329e9-573c-44de-a230-e1fce3ddd36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=\"\"\n",
    "a += \"lol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "069d87f8-182f-4aae-924d-6a43add510f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(500/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3083a6bc-dc86-4fea-b5b5-c5d34377b2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.333333333333334"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(8*100)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1b3946ba-9f00-467a-a405-8bc3ade98eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5001, 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ad0628-462f-4777-8aad-1f9133902eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['a'] = df['a'].apply(lambda x: x + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8eb24b7c-2ecb-46ee-a272-83d04d71a958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>transcript</th>\n",
       "      <th>playlist_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>introduction to vertex ai feature store</td>\n",
       "      <td>priyanka vergadia did you know that most of th...</td>\n",
       "      <td>ai and machine learning with google cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>illuminating the global fishing fleet through ...</td>\n",
       "      <td>speaker  oceanic ecosystems are threatened by ...</td>\n",
       "      <td>ai and machine learning with google cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hyperparameter tuning on vertex ai</td>\n",
       "      <td>priyanka vergadia hi im priyanka vergadia and ...</td>\n",
       "      <td>ai and machine learning with google cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>endtoend mlops with vertex ai</td>\n",
       "      <td>priyanka vergadia one of the biggest challenge...</td>\n",
       "      <td>ai and machine learning with google cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transformers explained understand the model be...</td>\n",
       "      <td>so if you remember anything about transformers...</td>\n",
       "      <td>the original transformer was designed for tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>using tensorflow hub for more productive machi...</td>\n",
       "      <td>yufeng guo code reuse is a central tenet of so...</td>\n",
       "      <td>where we explore the art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>training image amp text classification models ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ai and machine learning with google cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>deep learning vm images</td>\n",
       "      <td>yufeng guo dont you just love setting up your ...</td>\n",
       "      <td>ai and machine learning with google cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>how to import a keras model into tensorflowjs</td>\n",
       "      <td>yufeng guo tensorflowjs is awesome keras is aw...</td>\n",
       "      <td>and if you enjoyed it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>getting started with tensorflowjs</td>\n",
       "      <td>yufeng guo hey did you know that tensorflow no...</td>\n",
       "      <td>ai and machine learning with google cloud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0              introduction to vertex ai feature store   \n",
       "1    illuminating the global fishing fleet through ...   \n",
       "2                   hyperparameter tuning on vertex ai   \n",
       "3                        endtoend mlops with vertex ai   \n",
       "4    transformers explained understand the model be...   \n",
       "..                                                 ...   \n",
       "96   using tensorflow hub for more productive machi...   \n",
       "97   training image amp text classification models ...   \n",
       "98                             deep learning vm images   \n",
       "99       how to import a keras model into tensorflowjs   \n",
       "100                  getting started with tensorflowjs   \n",
       "\n",
       "                                            transcript  \\\n",
       "0    priyanka vergadia did you know that most of th...   \n",
       "1    speaker  oceanic ecosystems are threatened by ...   \n",
       "2    priyanka vergadia hi im priyanka vergadia and ...   \n",
       "3    priyanka vergadia one of the biggest challenge...   \n",
       "4    so if you remember anything about transformers...   \n",
       "..                                                 ...   \n",
       "96   yufeng guo code reuse is a central tenet of so...   \n",
       "97                                                 NaN   \n",
       "98   yufeng guo dont you just love setting up your ...   \n",
       "99   yufeng guo tensorflowjs is awesome keras is aw...   \n",
       "100  yufeng guo hey did you know that tensorflow no...   \n",
       "\n",
       "                                         playlist_name  \n",
       "0            ai and machine learning with google cloud  \n",
       "1            ai and machine learning with google cloud  \n",
       "2            ai and machine learning with google cloud  \n",
       "3            ai and machine learning with google cloud  \n",
       "4    the original transformer was designed for tran...  \n",
       "..                                                 ...  \n",
       "96                            where we explore the art  \n",
       "97           ai and machine learning with google cloud  \n",
       "98           ai and machine learning with google cloud  \n",
       "99                               and if you enjoyed it  \n",
       "100          ai and machine learning with google cloud  \n",
       "\n",
       "[101 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a170d632-c88f-47e1-aadd-6a9c43dfbbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_summary(df, k, device):\n",
    "    temp = df.loc[random.sample(range(df.shape[0]),k)]\n",
    "    store=[]\n",
    "    temp['summary'] = temp['transcript'].apply(lambda x:create_summaries(x,device,store))\n",
    "    temp = temp.reset_index().drop(['index'],axis=1)\n",
    "    temp['time_taken'] = store\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d1f503e9-8617-4ded-9df5-90ba1fd87708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>transcript</th>\n",
       "      <th>playlist_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>deep learningcs lec  continuous bag of words m...</td>\n",
       "      <td>so from here on so none of this that we covere...</td>\n",
       "      <td>deep learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>tensorflowjs  explore tensor operations throug...</td>\n",
       "      <td>whats up guys in this video were going to expl...</td>\n",
       "      <td>keras  python deep learning neural network api</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>cmu advanced nlp   language modeling and neura...</td>\n",
       "      <td>okay um this time im going to be talking about...</td>\n",
       "      <td>cmu advanced nlp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "1082  deep learningcs lec  continuous bag of words m...   \n",
       "1297  tensorflowjs  explore tensor operations throug...   \n",
       "2797  cmu advanced nlp   language modeling and neura...   \n",
       "\n",
       "                                             transcript  \\\n",
       "1082  so from here on so none of this that we covere...   \n",
       "1297  whats up guys in this video were going to expl...   \n",
       "2797  okay um this time im going to be talking about...   \n",
       "\n",
       "                                       playlist_name  \n",
       "1082                                   deep learning  \n",
       "1297  keras  python deep learning neural network api  \n",
       "2797                                cmu advanced nlp  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[random.sample(range(df.shape[0]),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9e39c19d-7277-4971-b0d6-4242f548bd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joshi.at/.conda/envs/ath_pytorch/lib/python3.7/site-packages/transformers/pipelines/base.py:1073: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  UserWarning,\n",
      "Your max_length is set to 500, but you input_length is only 79. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=39)\n",
      "Your max_length is set to 500, but you input_length is only 181. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=90)\n"
     ]
    }
   ],
   "source": [
    "new_df = subset_summary(df,10,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "60ee017d-50db-45c0-b57c-6ca4e8294e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.73138964176178"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.time_taken.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8e6428d2-f791-4b42-bab8-7c4a7093448b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.666666666666668"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(12*5000)/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f5184aaf-3a5e-40ed-8238-7621e4aa47b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "contains_non_string = df[df['transcript'].apply(type) != str].any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bcb1bcb1-48eb-423c-a061-7922a268099f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title             True\n",
       "transcript       False\n",
       "playlist_name     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contains_non_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3b830618-7b01-447f-8660-14ef0ad83727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>transcript</th>\n",
       "      <th>playlist_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>recovering global wildlife populations using ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ai and machine learning with google cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>integrate dialogflow with google chat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ai and machine learning with google cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>train and deploy models in cloud and onprem fr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ai and machine learning with google cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>reusable execution in production using papermi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ai and machine learning with google cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>87</td>\n",
       "      <td>optimizing tensorflow models for serving googl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ai and machine learning with google cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4945</th>\n",
       "      <td>4945</td>\n",
       "      <td>data augmentation explained</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deep learning fundamentals  intro to neural ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4947</th>\n",
       "      <td>4947</td>\n",
       "      <td>convolutional neural networks cnns explained</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deep learning fundamentals  intro to neural ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4949</th>\n",
       "      <td>4949</td>\n",
       "      <td>visualizing convolutional filters from a cnn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deep learning fundamentals  intro to neural ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4964</th>\n",
       "      <td>4964</td>\n",
       "      <td>finetuning a neural network explained</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deep learning fundamentals  intro to neural ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4965</th>\n",
       "      <td>4965</td>\n",
       "      <td>batch normalization batch norm explained</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deep learning fundamentals  intro to neural ne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                              title  \\\n",
       "16            16    recovering global wildlife populations using ml   \n",
       "33            33              integrate dialogflow with google chat   \n",
       "63            63  train and deploy models in cloud and onprem fr...   \n",
       "80            80  reusable execution in production using papermi...   \n",
       "87            87  optimizing tensorflow models for serving googl...   \n",
       "...          ...                                                ...   \n",
       "4945        4945                        data augmentation explained   \n",
       "4947        4947       convolutional neural networks cnns explained   \n",
       "4949        4949       visualizing convolutional filters from a cnn   \n",
       "4964        4964              finetuning a neural network explained   \n",
       "4965        4965           batch normalization batch norm explained   \n",
       "\n",
       "     transcript                                      playlist_name  \n",
       "16          NaN          ai and machine learning with google cloud  \n",
       "33          NaN          ai and machine learning with google cloud  \n",
       "63          NaN          ai and machine learning with google cloud  \n",
       "80          NaN          ai and machine learning with google cloud  \n",
       "87          NaN          ai and machine learning with google cloud  \n",
       "...         ...                                                ...  \n",
       "4945        NaN  deep learning fundamentals  intro to neural ne...  \n",
       "4947        NaN  deep learning fundamentals  intro to neural ne...  \n",
       "4949        NaN  deep learning fundamentals  intro to neural ne...  \n",
       "4964        NaN  deep learning fundamentals  intro to neural ne...  \n",
       "4965        NaN  deep learning fundamentals  intro to neural ne...  \n",
       "\n",
       "[73 rows x 4 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['transcript'].apply(type)!=str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5ae10528-a205-44d2-a433-d2681e53b9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['transcript'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "24d9dc9f-23f0-4898-9619-51e84f0ac63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('sample_summarized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "12d438a0-dd3a-45a1-b9bf-db3c3a3ec67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>transcript</th>\n",
       "      <th>playlist_name</th>\n",
       "      <th>summary</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural networks pt  relu in action</td>\n",
       "      <td>some people say i mispronounce value but that ...</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>the relu activation function is one of the mos...</td>\n",
       "      <td>6.519664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>braintobrain communication is coming</td>\n",
       "      <td>dear fellow scholars this is two minute papers...</td>\n",
       "      <td>two minute papers</td>\n",
       "      <td>braintobrain interface uses eeg to record brai...</td>\n",
       "      <td>4.811749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how to add a custom ner pipe in spacy and a cu...</td>\n",
       "      <td>hello and welcome back to the series on custom...</td>\n",
       "      <td>spacy for digital humanities with python tutor...</td>\n",
       "      <td>in this video im going to show you how to crea...</td>\n",
       "      <td>8.473709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>matplotlib tutorial   conclusion</td>\n",
       "      <td>what is going on everybody welcome to part  of...</td>\n",
       "      <td>matplotlib tutorial series  graphing in python</td>\n",
       "      <td>the wireframe is a slightly more complex versi...</td>\n",
       "      <td>6.793439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>machine learning tutorial python    logistic r...</td>\n",
       "      <td>this is part two of logistic regression tutori...</td>\n",
       "      <td>machine learning tutorial python  machine lear...</td>\n",
       "      <td>this is part two of the logistic regression tu...</td>\n",
       "      <td>10.672934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neural network architectures amp deep learning</td>\n",
       "      <td>welcome back so were talking about neural netw...</td>\n",
       "      <td>intro to data science</td>\n",
       "      <td>the basic building block of a neural network i...</td>\n",
       "      <td>9.124617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>equation for precision  intro to machine learning</td>\n",
       "      <td>so heres my final question which will be chall...</td>\n",
       "      <td>intro to machine learning</td>\n",
       "      <td>click on the corresponding items on the left s...</td>\n",
       "      <td>0.916600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>what is wordvec a simple explanation  deep lea...</td>\n",
       "      <td>word to work is a technique in computer scienc...</td>\n",
       "      <td>deep learning with tensorflow  keras and python</td>\n",
       "      <td>word to work is a technique in computer scienc...</td>\n",
       "      <td>13.923655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>barack obama intro to deep learning  mit s</td>\n",
       "      <td>this year i figured we could do something a li...</td>\n",
       "      <td>mit s introduction to deep learning</td>\n",
       "      <td>mit s is the official introductory course on d...</td>\n",
       "      <td>1.451634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>accelerated computer vision   convolutions fil...</td>\n",
       "      <td>so after learning to stand in your networks or...</td>\n",
       "      <td>computer vision</td>\n",
       "      <td>convolutional neural networks are a special ki...</td>\n",
       "      <td>4.625894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                 neural networks pt  relu in action   \n",
       "1               braintobrain communication is coming   \n",
       "2  how to add a custom ner pipe in spacy and a cu...   \n",
       "3                   matplotlib tutorial   conclusion   \n",
       "4  machine learning tutorial python    logistic r...   \n",
       "5     neural network architectures amp deep learning   \n",
       "6  equation for precision  intro to machine learning   \n",
       "7  what is wordvec a simple explanation  deep lea...   \n",
       "8         barack obama intro to deep learning  mit s   \n",
       "9  accelerated computer vision   convolutions fil...   \n",
       "\n",
       "                                          transcript  \\\n",
       "0  some people say i mispronounce value but that ...   \n",
       "1  dear fellow scholars this is two minute papers...   \n",
       "2  hello and welcome back to the series on custom...   \n",
       "3  what is going on everybody welcome to part  of...   \n",
       "4  this is part two of logistic regression tutori...   \n",
       "5  welcome back so were talking about neural netw...   \n",
       "6  so heres my final question which will be chall...   \n",
       "7  word to work is a technique in computer scienc...   \n",
       "8  this year i figured we could do something a li...   \n",
       "9  so after learning to stand in your networks or...   \n",
       "\n",
       "                                       playlist_name  \\\n",
       "0                                   machine learning   \n",
       "1                                  two minute papers   \n",
       "2  spacy for digital humanities with python tutor...   \n",
       "3     matplotlib tutorial series  graphing in python   \n",
       "4  machine learning tutorial python  machine lear...   \n",
       "5                              intro to data science   \n",
       "6                          intro to machine learning   \n",
       "7    deep learning with tensorflow  keras and python   \n",
       "8                mit s introduction to deep learning   \n",
       "9                                    computer vision   \n",
       "\n",
       "                                             summary  time_taken  \n",
       "0  the relu activation function is one of the mos...    6.519664  \n",
       "1  braintobrain interface uses eeg to record brai...    4.811749  \n",
       "2  in this video im going to show you how to crea...    8.473709  \n",
       "3  the wireframe is a slightly more complex versi...    6.793439  \n",
       "4  this is part two of the logistic regression tu...   10.672934  \n",
       "5  the basic building block of a neural network i...    9.124617  \n",
       "6  click on the corresponding items on the left s...    0.916600  \n",
       "7  word to work is a technique in computer scienc...   13.923655  \n",
       "8  mit s is the official introductory course on d...    1.451634  \n",
       "9  convolutional neural networks are a special ki...    4.625894  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1201b68-bcf3-4e80-8caf-39b3ab6c7aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ath_pytorch",
   "language": "python",
   "name": "ath_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
